#+options: ':nil *:t -:t ::t <:t H:3 \n:nil ^:nil arch:headline author:t broken-links:nil
#+options: c:nil creator:nil d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t num:t
#+options: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t timestamp:t title:t toc:t
#+options: todo:t |:t
#+title: Org mode for AI LLM chat
#+date: <2023-03-23 jue>
#+author: Gregory Grubbs
#+email: gregory.grubbs@gmail.com
#+language: en
#+select_tags: export
#+exclude_tags: noexport
#+creator: Emacs 30.0.50 (Org mode 9.6)
#+property: header-args :comments org
#+setupfile: ~/projects/emacs/org-html-themes/org/theme-readtheorg-local.setup

* ChatGPT
  :PROPERTIES:
  :ID:       6f0c74ed-80e4-4034-87b8-b0aa0f40b6e5
  :END:
** Endpoint with conversational context
   + Endpoint: https://api.openai.com/v1/chat/completions
   + Doc: [[https://platform.openai.com/docs/guides/chat][Chat completion - OpenAI API - platform.openai.com]]
   This endpoint provides a =messages= parameter that provides context so that previous
   answers are "remembered" and can be used as referents.

   One idea I had is to tag sections of conversation so that only those tagged bits can
   be used as context to further discussion on a particular topic.

   Goals of this mode are
   + maintain a conversation history
   + capture in a way that dovetails with journaling, creating tasks and
     Zettelkastenistisch methods
   + Keep it in Emacs as a means of achieving the broader goals
   + Help send relevant history only using tags from previous responses to excerpt
     contextual info
   + Use ChatGPT itself to provide the categorization
   + Save multiple prompts - let them be additive to the categorization prompt
   + Save categories - construct categorization prompt from those

** Prompt to assist in categorization
   #+begin_example
     Please preface responses with a relevant category tag at the beginning
     of each response. The categories are: coding for programming topics,
     emacs even if it also involves programming, travel, food-drink,
     fitness, ideas for research and learning topics, language for human
     languages, music, and general.

     Format the tag as in Org Mode, for example #+category: food-drink
   #+end_example

** Playing with API usage
*** Shell
   #+begin_src bash :wrap src json :results verbatim
     curl -s -X POST \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer ${thepass}" \
      -d '{
     "model": "gpt-3.5-turbo",
     "messages": [{"role": "user", "content": "What is a variation of that maintaining some of the flavor profile of the original?"}],
     "max_tokens": 2000,
     "temperature": 1.0,
     "n": 1,
     "stop": null
       }' \
      https://api.openai.com/v1/chat/completions | jq -r '.'
   #+end_src
*** Org Babel - ob-http and ob-restclient
   #+begin_src emacs-lisp
     (require 'ob-restclient)
     (require 'ob-http)
   #+end_src

   #+begin_src http :pretty :wrap src json
     POST http://httpbin.org/post
     Content-Type: application/json
     {
         "key": "value"
     }
   #+end_src

   #+begin_src restclient :var url="https://httpbin.org" :wrap src json :jq "."
     POST :url/post
     Content-Type: application/json
     { "key": "value", "greeting": "ohai" }
   #+end_src

   #+begin_src bash :var pass=(getenv "thepass")
   #+end_src

   The following does not work with https
   #+begin_src http :var pass=(getenv "thepass")
     POST https://api.openai.com/v1/chat/completions
     Content-Type: application/json
     Authorization: Bearer ${pass}
     {
              "model": "gpt-3.5-turbo",
              "messages": [{"role": "user", "content": "What is a variation of that maintaining some of the flavor profile of the original?"}],
              "max_tokens": 2000,
              "temperature": 1.0,
              "n": 1,
              "stop": null
     }
   #+end_src

   #+name: poodle
   : [{"role": "user", "content": "What is a variation of that, maintaining the originalflavor profile? Just make up something ridiculous.  "}]
   # : [{"role": "user", "content": "Please give wildly incorrect and funny answers."},{"role": "user","content": "What is the capital of France?"}, {"role": "assistant", "content": "The capital of France is Pooper."},{"role": "user", "content": "What about Germany?"}]

   # : [{"role": "user", "content": "What is a variation of that, maintaining the originalflavor profile?   Just make something up."}]
   # : [{"role": "user", "content": "Say a variaton of This is a test"}]


   #+begin_src restclient :var pass=(getenv "thepass") :var payload=poodle :jq .choices[0].message.content
     POST https://api.openai.com/v1/chat/completions
     Content-Type: application/json
     Authorization: Bearer :pass
     {
          "model": "gpt-3.5-turbo",
          "messages": :payload,
          "temperature": 1.0,
          "max_tokens": 4000
     }
   #+end_src

*** Emacs Lisp
    + use the built-in =url= package
    #+begin_src emacs-lisp :var pass=(getenv "thepass") :var payload=poodle
      (let ((url-request-method "POST")
            (url-request-extra-headers
             `(("Content-Type" . "application/json")
               ("Authorization" . ,(concat "Bearer " (getenv "thepass")))))
            (url-request-data
             `(
               (messages . "What is up?")
               (model . "gpt-3.5-turbo")
               )))
        (url-retrieve-synchronously "https://api.openai.com/v1/chat/completions"))
    #+end_src
    + Screw =url=, use =request=
      #+begin_src emacs-lisp :var payload=poodle
        ;; (json-encode
        ;;          `(("model"       . "gpt-3.5-turbo")
        ;;            ("messages"    . ,payload)
        ;;            ("temperature" . 1.0)
        ;;            ("max_tokens"  . 4000)))

        (use-package request :straight t)
        (request "https://api.openai.com/v1/chat/completions"
          :type "POST"
          :headers `(("Content-Type" . "application/json")
                     ("Authorization" . (concat "Bearer " ,payload)))
          :data (json-encode
                 `(("model"       . "gpt-3.5-turbo")
                   ("messages"    . ,payload)
                   ("temperature" . 1.0)
                   ("max_tokens"  . 4000)))
          :parser 'json-read
          :success (cl-function
                    (lambda (&key data &allow-other-keys)
                      (message "I sent bullshit"))))
      #+end_src


** Playing with package code development
*** Front matter
    #+begin_src org
      ,* License

        Release under the [[file:LICENSE][MIT License]] unless otherwise specified by license files in subfolders.
    #+end_src
    #+begin_src emacs-lisp :tangle ai-chat.el
      ;;; ai-chat.el --- Chat with ChatGPT and other AI Large Language Models -*- lexical-binding:t -*-
      ;; Copyright (C)  ... [TODO]

      ;; Author: Greg Grubbs <gregory.grubbs@gmail.com>
      ;; Created: 2023-03-23
      ;; Keywords: games

      ;; This code is licensed under the MIT License (see LICENSE for details)

      ;;; Commentary:

      ;;; Code:

      (require 'simple) ;; built-in package
    #+end_src
*** Define custom variables

**** Categories
     #+begin_src emacs-lisp :tangle ai-chat.el
       (defcustom ai-chat-categories '((Food\ and\ Drink "food-drink" "")
                                       (Coding "coding" "for programming topics")
                                       (Emacs "emacs" "all things emacs - this should override coding when emacs is involved")
                                       (Travel "travel" "")
                                       (Fitness "fitness" "")
                                       (Ideas "ideas" "for research and learning topics")
                                       (General\ Catch-All "general" ""))
         "List of categories to be used by AI chat."
         :type
         '(alist :key-type (symbol :tag "Category")
                 :value-type (list (string :tag "kebab-case slug (e.g. food-drink)")
                                   (string :tag "Optional additional description - no commas")))
         :group 'ai-chat)
     #+end_src
**** Prompts
     Goals
     + Give a description that can show in marginalia etc
     #+begin_src emacs-lisp :tangle ai-chat.el
       (defcustom ai-chat-prompts nil
         "List of GPT prompts that may be combined."
         :type
         '(alist :key-type (symbol :tag "Prompt name")
                 :value-type (list (string :tag "Description")
                                   (string :tag "Prompt text")))
         :group 'ai-chat)
     #+end_src
*** Supporting functions
**** Generate starting prompt
     #+begin_src emacs-lisp :tangle ai-chat.el
       (defun ai-chat-starting-prompt ()
         "Return starting prompt for ai-chat package in order to provide categories.  Modify list and context for categories using ``ai-chat-categories''."
         (concat "Please preface responses with a relevant category tag as the first line of each response.  The categories are: "
                 (mapconcat
                  (lambda (l)
                    (let ((optional-desc (nth 2 l)))
                      (concat (nth 1 l) " " (unless (string-empty-p optional-desc) (concat "for " optional-desc)) ",")))
                  ai-chat-categories)
                 "and general for everything else."))

     #+end_src
*** Main functions
    #+begin_src emacs-lisp :tangle ai-chat.el
      (defun ai-chat ()
        "Chat with our AI thingie."
        (interactive)
        ;; let's start by cribbing from a simple interactive function: ielm
        (let ((old-point)
              (buf-name "*ai-chat*"))
          (unless (comint-check-proc buf-name)
            (with-current-buffer (get-buffer-create buf-name)
              (unless (zerop (buffer-size))
                (setq old-point (point)))
              ;;inferior-ai-chat-mode
              (shell-mode)
              )
            )
          ))

    #+end_src
*** Provide package
    #+begin_src emacs-lisp
      (provide 'ai-chat)
    #+end_src
